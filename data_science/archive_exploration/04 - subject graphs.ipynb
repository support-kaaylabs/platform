{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# images of graphy subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "plt.rcParams['figure.figsize'] = (20, 20)\n",
    "\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "from umap import UMAP\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(input_list):\n",
    "    return [item \n",
    "            for sublist in input_list \n",
    "            for item in sublist]\n",
    "\n",
    "def clean(subject):\n",
    "    return subject.strip().lower().replace('<p>', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('data/calm_records.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AltRefNo'] = df['AltRefNo'].dropna().apply(lambda x: x[0])\n",
    "df['Subject'] = df['Subject'].dropna().apply(lambda x: list(map(clean, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_subjects = flatten(df['Subject'].dropna().tolist())\n",
    "subjects = list(set(map(clean, dirty_subjects)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency = pd.DataFrame(data=0, \n",
    "                         index=subjects, \n",
    "                         columns=subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f69b4428ab24949aa902c1d651bf638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16664), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for row_of_subjects in tqdm(df['Subject'].dropna()):\n",
    "    \n",
    "    clean_row = list(set([clean(subject) for subject in row_of_subjects]))\n",
    "    \n",
    "    for subject_1, subject_2 in itertools.product(clean_row, repeat=2):\n",
    "        adjacency[subject_1][subject_2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_adjacency(adjacency)\n",
    "nx.draw_spring(G, node_size=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quite complicated\n",
    "lets get rid of the rare subjects and only look at common ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subject_counts = pd.Series(map(clean, dirty_subjects)).value_counts() \n",
    "rare_subjects = subject_counts[subject_counts < 10].index.values\n",
    "\n",
    "len(subjects) - len(rare_subjects) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mini_adjacency = (adjacency\n",
    "                  .drop(rare_subjects, axis=0)\n",
    "                  .drop(rare_subjects, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_adjacency = adjacency.mask(mini_adjacency < 10, 0)\n",
    "mini_adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_adjacency(mini_adjacency)\n",
    "\n",
    "nx.draw_spring(G, node_size=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lots of orphans... lets get rid of those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orphans = [subject for subject in mini_adjacency.index.values\n",
    "           if mini_adjacency[subject].sum() == mini_adjacency[subject][subject]]\n",
    "\n",
    "mini_adjacency = (adjacency\n",
    "                  .drop(orphans, axis=0)\n",
    "                  .drop(orphans, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_adjacency(mini_adjacency)\n",
    "\n",
    "nx.draw(G, node_size=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_2d = pd.DataFrame(UMAP(n_components=2)\n",
    "                            .fit_transform(mini_adjacency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 15\n",
    "\n",
    "embedding_2d['labels'] = (AgglomerativeClustering(n_clusters)\n",
    "                          .fit_predict(embedding_2d.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_spring(G, node_size=40, \n",
    "               node_color=embedding_2d['labels'],\n",
    "               alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this thing is a real mess - subjects behave weirdly, and seem to either be weirdo one-offs, or super connected to everything. Still we can extract little structures and clusters. It's fine. Let's start using them.\n",
    "\n",
    "# connect records by subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_subjects = df[~df['Subject'].isna()].set_index('AltRefNo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicies = with_subjects.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicies = np.nan_to_num(indicies).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_subjects.index = indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138836116"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(itertools.combinations(indicies, r=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency = pd.DataFrame(data=0,\n",
    "                         index=indicies,\n",
    "                         columns=indicies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c2888b62b544ac8b71b6189d440cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=138836116), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pimharr/anaconda3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/pimharr/anaconda3/lib/python3.6/site-packages/tqdm/_monitor.py\", line 62, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/Users/pimharr/anaconda3/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-2b29a84d657f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrecord_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord_2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindicies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msubjects_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_subjects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Subject'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrecord_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msubjects_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_subjects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Subject'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrecord_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0madjacency\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrecord_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrecord_2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubjects_1\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0msubjects_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "for record_1, record_2 in tqdm(list(itertools.combinations(indicies, r=2))):\n",
    "    subjects_1 = set(with_subjects['Subject'][record_1])\n",
    "    subjects_2 = set(with_subjects['Subject'][record_2])\n",
    "    adjacency[record_1][record_2] = len(subjects_1 & subjects_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orphans = [record for record in adjacency.index.values\n",
    "           if adjacency[record].sum() == adjacency[record][record]]\n",
    "\n",
    "adjacency = (adjacency\n",
    "             .drop(orphans, axis=0)\n",
    "             .drop(orphans, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_adjacency(adjacency)\n",
    "\n",
    "nx.draw(G, node_size=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_2d = pd.DataFrame(UMAP(n_components=2)\n",
    "                            .fit_transform(adjacency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 15\n",
    "\n",
    "embedding_2d['labels'] = (AgglomerativeClustering(n_clusters)\n",
    "                          .fit_predict(embedding_2d.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_spring(G, node_size=40, \n",
    "               node_color=embedding_2d['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# connect records by subject _and_ hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_ref_no = 'GC'\n",
    "\n",
    "codes_as_str = sorted(df['AltRefNo'][df['AltRefNo']\n",
    "                                     .str.startswith(alt_ref_no)\n",
    "                                     .fillna(False)]\n",
    "                      .tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = {code: re.split('/|\\.', code.strip())\n",
    "         for code in codes_as_str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_tree = pd.DataFrame(data=0,\n",
    "                              index=codes_as_str,\n",
    "                              columns=codes_as_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for parent_str, parent_list in tqdm(codes.items()):\n",
    "    for child_str, child_list in codes.items():\n",
    "        if child_list == parent_list + [child_list[-1]]:\n",
    "            adjacency_tree[parent_str][child_str] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ack = adjacency_tree.add(adjacency, fill_value=0).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orphans = [subject for subject in ack.index.values\n",
    "           if ack[subject].sum() == ack[subject][subject]]\n",
    "\n",
    "ack = (ack\n",
    "       .drop(orphans, axis=0)\n",
    "       .drop(orphans, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G = nx.from_pandas_adjacency(ack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_spring(G, node_size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_2d = pd.DataFrame(UMAP(n_components=2)\n",
    "                            .fit_transform(ack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 15\n",
    "\n",
    "embedding_2d['labels'] = (AgglomerativeClustering(n_clusters)\n",
    "                          .fit_predict(embedding_2d.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_spring(G, node_size=40, \n",
    "               node_color=embedding_2d['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GC/2',\n",
       " 'GC/20',\n",
       " 'GC/200',\n",
       " 'GC/201',\n",
       " 'GC/202',\n",
       " 'GC/203',\n",
       " 'GC/205',\n",
       " 'GC/207',\n",
       " 'GC/208',\n",
       " 'GC/209',\n",
       " 'GC/21',\n",
       " 'GC/210',\n",
       " 'GC/211',\n",
       " 'GC/213',\n",
       " 'GC/214',\n",
       " 'GC/215',\n",
       " 'GC/216',\n",
       " 'GC/217',\n",
       " 'GC/218',\n",
       " 'GC/219',\n",
       " 'GC/22',\n",
       " 'GC/220',\n",
       " 'GC/221',\n",
       " 'GC/222',\n",
       " 'GC/223',\n",
       " 'GC/224',\n",
       " 'GC/226',\n",
       " 'GC/227',\n",
       " 'GC/228',\n",
       " 'GC/23',\n",
       " 'GC/231',\n",
       " 'GC/232',\n",
       " 'GC/233',\n",
       " 'GC/236',\n",
       " 'GC/237',\n",
       " 'GC/238',\n",
       " 'GC/239',\n",
       " 'GC/24',\n",
       " 'GC/240',\n",
       " 'GC/241',\n",
       " 'GC/244',\n",
       " 'GC/248',\n",
       " 'GC/249',\n",
       " 'GC/25',\n",
       " 'GC/250',\n",
       " 'GC/251',\n",
       " 'GC/252',\n",
       " 'GC/253/A/1',\n",
       " 'GC/253/A/10',\n",
       " 'GC/253/A/11',\n",
       " 'GC/253/A/12',\n",
       " 'GC/253/A/13',\n",
       " 'GC/253/A/14',\n",
       " 'GC/253/A/15',\n",
       " 'GC/253/A/17',\n",
       " 'GC/253/A/18',\n",
       " 'GC/253/A/19',\n",
       " 'GC/253/A/2',\n",
       " 'GC/253/A/20',\n",
       " 'GC/253/A/21',\n",
       " 'GC/253/A/22',\n",
       " 'GC/253/A/23',\n",
       " 'GC/253/A/24',\n",
       " 'GC/253/A/25',\n",
       " 'GC/253/A/26',\n",
       " 'GC/253/A/27',\n",
       " 'GC/253/A/28',\n",
       " 'GC/253/A/29',\n",
       " 'GC/253/A/30',\n",
       " 'GC/253/A/31',\n",
       " 'GC/253/A/32',\n",
       " 'GC/253/A/33',\n",
       " 'GC/253/A/34',\n",
       " 'GC/253/A/35',\n",
       " 'GC/253/A/36',\n",
       " 'GC/253/A/37',\n",
       " 'GC/253/A/38',\n",
       " 'GC/253/A/39',\n",
       " 'GC/253/A/4',\n",
       " 'GC/253/A/40',\n",
       " 'GC/253/A/41',\n",
       " 'GC/253/A/42',\n",
       " 'GC/253/A/43',\n",
       " 'GC/253/A/44',\n",
       " 'GC/253/A/45',\n",
       " 'GC/253/A/47',\n",
       " 'GC/253/A/48',\n",
       " 'GC/253/A/49',\n",
       " 'GC/253/A/5',\n",
       " 'GC/253/A/51',\n",
       " 'GC/253/A/52',\n",
       " 'GC/253/A/53',\n",
       " 'GC/253/A/54',\n",
       " 'GC/253/A/55',\n",
       " 'GC/253/A/56',\n",
       " 'GC/253/A/58',\n",
       " 'GC/253/A/59',\n",
       " 'GC/253/A/6',\n",
       " 'GC/253/A/60',\n",
       " 'GC/253/A/62',\n",
       " 'GC/253/A/7',\n",
       " 'GC/253/A/8',\n",
       " 'GC/253/A/9',\n",
       " 'GC/253/B/1',\n",
       " 'GC/253/B/2',\n",
       " 'GC/253/B/3',\n",
       " 'GC/253/B/4',\n",
       " 'GC/253/B/5',\n",
       " 'GC/253/C/1',\n",
       " 'GC/253/C/2',\n",
       " 'GC/254',\n",
       " 'GC/256',\n",
       " 'GC/257',\n",
       " 'GC/258',\n",
       " 'GC/259',\n",
       " 'GC/26',\n",
       " 'GC/260',\n",
       " 'GC/261',\n",
       " 'GC/262',\n",
       " 'GC/263',\n",
       " 'GC/265',\n",
       " 'GC/267',\n",
       " 'GC/268',\n",
       " 'GC/269',\n",
       " 'GC/27',\n",
       " 'GC/270',\n",
       " 'GC/271',\n",
       " 'GC/273',\n",
       " 'GC/274',\n",
       " 'GC/276',\n",
       " 'GC/278',\n",
       " 'GC/28',\n",
       " 'GC/281',\n",
       " 'GC/29'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(set(map(str.strip, np.array(codes_as_str).astype(str))) & \n",
    " set(map(str.strip, np.array(indicies).astype(str))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# images of graphy subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "plt.rcParams['figure.figsize'] = (20, 20)\n",
    "\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "from umap import UMAP\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(input_list):\n",
    "    return [item \n",
    "            for sublist in input_list \n",
    "            for item in sublist]\n",
    "\n",
    "def clean(subject):\n",
    "    return subject.strip().lower().replace('<p>', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('data/calm_records.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AltRefNo'] = df['AltRefNo'].dropna().apply(lambda x: x[0])\n",
    "df['Subject'] = df['Subject'].dropna().apply(lambda x: list(map(clean, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_subjects = flatten(df['Subject'].dropna().tolist())\n",
    "subjects = list(set(map(clean, dirty_subjects)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency = pd.DataFrame(data=0, \n",
    "                         index=subjects, \n",
    "                         columns=subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row_of_subjects in tqdm(df['Subject'].dropna()):\n",
    "    \n",
    "    clean_row = list(set([clean(subject) for subject in row_of_subjects]))\n",
    "    \n",
    "    for subject_1, subject_2 in itertools.product(clean_row, repeat=2):\n",
    "        adjacency[subject_1][subject_2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_adjacency(adjacency)\n",
    "nx.draw_spring(G, node_size=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quite complicated\n",
    "lets get rid of the rare subjects and only look at common ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subject_counts = pd.Series(map(clean, dirty_subjects)).value_counts() \n",
    "rare_subjects = subject_counts[subject_counts < 10].index.values\n",
    "\n",
    "len(subjects) - len(rare_subjects) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mini_adjacency = (adjacency\n",
    "                  .drop(rare_subjects, axis=0)\n",
    "                  .drop(rare_subjects, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_adjacency = adjacency.mask(mini_adjacency < 10, 0)\n",
    "mini_adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_adjacency(mini_adjacency)\n",
    "\n",
    "nx.draw_spring(G, node_size=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lots of orphans... lets get rid of those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orphans = [subject for subject in mini_adjacency.index.values\n",
    "           if mini_adjacency[subject].sum() == mini_adjacency[subject][subject]]\n",
    "\n",
    "mini_adjacency = (adjacency\n",
    "                  .drop(orphans, axis=0)\n",
    "                  .drop(orphans, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_adjacency(mini_adjacency)\n",
    "\n",
    "nx.draw(G, node_size=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_2d = pd.DataFrame(UMAP(n_components=2)\n",
    "                            .fit_transform(mini_adjacency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 15\n",
    "\n",
    "embedding_2d['labels'] = (AgglomerativeClustering(n_clusters)\n",
    "                          .fit_predict(embedding_2d.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_spring(G, node_size=40, \n",
    "               node_color=embedding_2d['labels'],\n",
    "               alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this thing is a real mess - subjects behave weirdly, and seem to either be weirdo one-offs, or super connected to everything. Still we can extract little structures and clusters. It's fine. Let's start using them.\n",
    "\n",
    "# connect records by subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_subjects = df[~df['Subject'].isna()].set_index('AltRefNo').sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicies = np.nan_to_num(with_subjects.index.values).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_subjects.index = indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency = pd.DataFrame(data=0,\n",
    "                         index=indicies,\n",
    "                         columns=indicies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record_1, record_2 in tqdm(list(itertools.combinations(indicies, r=2))):\n",
    "    subjects_1 = set(with_subjects['Subject'][record_1])\n",
    "    subjects_2 = set(with_subjects['Subject'][record_2])\n",
    "    adjacency[record_1][record_2] = len(subjects_1 & subjects_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orphans = [record for record in adjacency.index.values\n",
    "           if adjacency[record].sum() == adjacency[record][record]]\n",
    "\n",
    "adjacency = (adjacency\n",
    "             .drop(orphans, axis=0)\n",
    "             .drop(orphans, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_adjacency(adjacency)\n",
    "\n",
    "nx.draw(G, node_size=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_2d = pd.DataFrame(UMAP(n_components=2)\n",
    "                            .fit_transform(adjacency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 15\n",
    "\n",
    "embedding_2d['labels'] = (AgglomerativeClustering(n_clusters)\n",
    "                          .fit_predict(embedding_2d.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_spring(G, node_size=40, \n",
    "               node_color=embedding_2d['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# connect records by subject _and_ hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_ref_no = 'GC'\n",
    "\n",
    "codes_as_str = sorted(df['AltRefNo'][df['AltRefNo']\n",
    "                                     .str.startswith(alt_ref_no)\n",
    "                                     .fillna(False)]\n",
    "                      .tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = {code: re.split('/|\\.', code.strip())\n",
    "         for code in codes_as_str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_tree = pd.DataFrame(data=0,\n",
    "                              index=codes_as_str,\n",
    "                              columns=codes_as_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for parent_str, parent_list in tqdm(codes.items()):\n",
    "    for child_str, child_list in codes.items():\n",
    "        if child_list == parent_list + [child_list[-1]]:\n",
    "            adjacency_tree[parent_str][child_str] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ack = adjacency_tree.add(adjacency, fill_value=0).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orphans = [subject for subject in ack.index.values\n",
    "           if ack[subject].sum() == ack[subject][subject]]\n",
    "\n",
    "ack = (ack\n",
    "       .drop(orphans, axis=0)\n",
    "       .drop(orphans, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_adjacency(ack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_spring(G, node_size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_2d = pd.DataFrame(UMAP(n_components=2)\n",
    "                            .fit_transform(ack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 15\n",
    "\n",
    "embedding_2d['labels'] = (AgglomerativeClustering(n_clusters)\n",
    "                          .fit_predict(embedding_2d.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_spring(G, node_size=40, \n",
    "               node_color=embedding_2d['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(set(map(str.strip, np.array(codes_as_str).astype(str))) & \n",
    " set(map(str.strip, np.array(indicies).astype(str))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
